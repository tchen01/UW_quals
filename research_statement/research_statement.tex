\documentclass[11pt]{article}

% Document Details
\newcommand{\CLASS}{Research Statement}
\newcommand{\assigmentnum}{}

\usepackage[margin=1.1in]{geometry}
\input{../TeX_headers/title.tex} % Title Styling
\input{../TeX_headers/styling.tex} % General Styling



\usepackage{fontspec}

\hypersetup{
    hidelinks=true       % false: boxed links; true: colored links
}

%\pagenumbering{gobble}


\newenvironment{problem}[1]{\vspace{2em}{\large\sffamily\textbf{#1}}\itshape\par}{}


\begin{document}
\maketitle
\vspace{2em}

\textbf{Broadly, I intend to incorporate parallelism and randomness into existing algorithms for difficult linear algebra problems.}

\textbf{talk about short and long term plans}


I have I have been working with Anne Greenbaum on variants of the conjugate gradient method for the last two quarters. Conjugate gradient is a standard method for solving Hermitian positive definite linear systems, and is frequently used for problems involving discretizations of physical systems. In exact arithmetic, like most Krylov space methods, the conjugate gradient algorithm will solve a \( n\times n \) system at most \( n \) steps. However, when conjugate gradient algorithms are implemented in floating point arithmetic, this is no longer the case.

\textbf{Talk about what skills are required for this type of problem.}


Recently there has been interest in parallelizeable algorithms for conjugate gradient.
While all such variants are equivalent in exact arithmetic, they behave differently in floating point arithmetic. In particular, the rate of convergence (in terms of the iteration count) and the eventual attained accuracy may be significantly worse than the standard (Hestenes and Stiefel) implementation on certain problems. This means that even if a single iteration can be made faster through parallelization, the total time needed to compute the solution may not be improved. 

It is of obvious interest to understand why different variance behave differently, and our eventual hope is to develop a parallelizeable algorithm which is not as susceptible to numerical instabilities as the current algorithms. 

At the moment most of our work centers around trying to understand the algorithms in terms of the properties above. 

In \cite{perturbed_lanczos} Greenbaum showed, that under the right conditions, finite precision Lanczos iteration applied to a matrix \( A \) could be viewed as exact Lanczos applied to a larger matrix \( T \), whose eigenvalues are clustered near those of \( A \).

Of interest are 1. how orthogonal successive residual vectors are, 2. , and 3. \textbf{fill out}.


\textbf{talk about what can be parallelized}






In order to help build the foundational knowledge required to work on such problems, I have taken the AMATH 584/585/586, and the AMATH 561/562/563 sequences. In addition I have taken AMATH 567 and MATH 514. In these courses I have explicitly made an effort to improve my programming as well as to improve my intuition as to when rigor is and is not necessary. My background in mathematics meant that I had the tendency to get lost in the details of a problem, rather than focusing on the big picture. Over the past year I have become significantly better at starting with big picture and working out the details as necessary. This has allowed me to improve my intuition and spend time thinking the important parts of a problem.

Over the past few years I have made a point to expose myself to a variety of software libraries including GPU libraries such CUDA and Tensorflow, scientific computing libraries and languages such as C/C++, Numpy/Scipy, and Julia, symbolic manipulation software such as Sympy and Mathematica, and visualization software such as Matplotlib and TikZ. In every project and assignment I make an effort to ensure that my code is efficient and scalable, even if the problems no not require this. These practices now will carry over well when working much larger problems/data in the future.

In addition to broadening my tool set, I have attempted to use open source software whenever possible. I believe that access to a quality education and quality educational resources should not be dependent on socioeconomic status or geography, and forcing students to pay for software and textbooks places an unfair and unnecessary burden on students from underprivileged backgrounds. 
I have made hundreds of pages of my personal course notes, homework assignments, and code openly available on Github. In particular, I have ported every MATLAB prgram which has been part of an assignment to an analogous python program. It is my hope that these actions will help reduce the reliance on closed source software among future students in our department.


Finally, there are near future plans in place to continue building the groundwork for my research. Most notably, I will be doing a reading with Ioana Dumitriu during the fall quarter. 


I also intend to take AMATH 515 in the winter.

During this reading I will study random linear algebra in order to start to understand how 

During the last few months I have had to put aside research work in order to prepare for the qualifying exams. I look forward to being able to return my mental focus to these projects in the near future. 



\bibliographystyle{siam}
\bibliography{refs.bib}


\end{document}
