\documentclass[12pt]{article}
\usepackage[T1]{fontenc}

% Document Details
\newcommand{\CLASS}{Stochastics}
\newcommand{\assigmentnum}{Methods and Problems}


\usepackage[margin = 1in, top = 1.25in, bottom = 1.in]{geometry}
\input{../../TeX_headers/title.tex} % Title Styling
\input{../../TeX_headers/sfftoc.tex} % ToC Styling
\input{../../TeX_headers/styling.tex} % General Styling
\input{../../TeX_headers/section.tex} % Section Styling
\input{../../TeX_headers/code.tex} % Code Display Setup
\input{../../TeX_headers/math.tex} % Math shortcuts
\input{../../TeX_headers/problem.tex} % Math shortcuts
\input{../../TeX_headers/proof.tex} % Math shortcuts


\hypersetup{
    colorlinks=true,       % false: boxed links; true: colored links
    linkcolor=violet,          % color of internal links (change box color with linkbordercolor)
    citecolor=green,        % color of links to bibliography
    filecolor=magenta,      % color of file links
    urlcolor=cyan           % color of external links
}

\setlength{\headheight}{15pt}
\newcommand{\note}[1]{\textcolor{red}{\textit{Note:} #1}}

% overwrite old problem class to be able to add to ToC
\let\savedprob=\problem%
\def\problem[#1]{\pagebreak\phantomsection\addcontentsline{toc}{subsection}{#1}\savedprob[#1]\label{#1}}


\begin{document}
\maketitle

\pagebreak
\tableofcontents

%%%%%%%%%%%%%%%%%%%%%
%    Useful Info    %
%%%%%%%%%%%%%%%%%%%%%
\pagebreak
\section{Random Varibles and Distributions}
\subsection{Basic Definitions}
\subsubsection{Probability Mass Function (discrete)} 
\begin{align*}
    p(k) = \PP(X = k)
\end{align*}

\subsubsection{Probability Density Function (continuous)} 
\begin{align*}
    f(x)\d x = \PP(X \in [x,x+\d x))
\end{align*}

\subsubsection{Cumulative Density Function}
\begin{align*}
    F(x) = \PP(X < x ) = 
    \begin{cases}
        \sum_{k=0}^{\lfloor x \rfloor} p(k) & \text{discrete} \\
        \int_{-\infty}^{x} f(x)\d x & \text{continuous}
    \end{cases}
\end{align*}

Can obtain probability density function by,
\begin{align*}
    f(x) = \dd{}{x} F(x)
\end{align*}


\subsubsection{Probability Generating Function}
\begin{align*}
    G(z) = \EE\left[z^X\right] = p(0) + p(1)z + p(2)z^2 + p(3)z^3 + \cdots
\end{align*}
Can obtain probability mass function by,
\begin{align*}
    p(k) = \frac{1}{k!} \left[ \dd[k]{}{z} G(z) \right]_{z=0}
\end{align*}


\subsubsection{Characteristic Function}
\begin{align*}
    \phi(t) = \EE\left[e^{itX}\right] 
\end{align*}

\note{WHAT DO WE USE THIS FOR??}


\subsection{Bernoulli}
Models if a heads is flipped for a biased coin.
\begin{center}
\def\arraystretch{1.5}
\begin{tabular}{|r|l|} \hline
    Parameters & \( p\in[0,1] \) \\ \hline
    Support & \( \{0,1\} \) \\ \hline
    PMF & \( \begin{cases} 1-p & k=0 \\ p & k=1 \end{cases} \) \\ \hline 
    Mean & \( p \) \\ \hline
    Variance & \( p(1-p) \) \\ \hline
    PGF & \( (1-p)+pz \) \\ \hline
    CF & \( (1-p)+pe^{it} \)\\ \hline
\end{tabular}
\end{center}


\subsection{Binomial}
Models the number of heads when flipping a biased coin \( n \) times.
\begin{center}
\def\arraystretch{1.5}
\begin{tabular}{|r|l|} \hline
    Parameters & \( p\in[0,1],n\in \NN_{\geq 0} \) \\ \hline
    Support & \( \{0,1,\ldots, n\} \) \\ \hline
    PMF & \( \binom{n}{k} p^k(1-p)^{n-k} \) \\ \hline 
    Mean & \( np \) \\ \hline
    Variance & \( np(1-p) \) \\ \hline
    PGF & \( [(1-p)+pz]^n \) \\ \hline
    CF & \( [(1-p) + pe^{it}]^n \)\\ \hline
\end{tabular}
\end{center}


\subsection{Geometric}
Models the number of flips of a biased coin required to flip a heads.
\begin{center}
\def\arraystretch{1.5}
\begin{tabular}{|r|l|} \hline
    Parameters & \( p\in[0,1] \) \\ \hline
    Support & \( \{1,\ldots, n\} \) \\ \hline
    PMF & \( p(1-p)^{k-1} \) \\ \hline 
    CDF & \( 1-(1-p)^k \) \\ \hline
    Mean & \( 1/p \) \\ \hline
    Variance & \( (1-p)/p^2 \) \\ \hline
    PGF & \( ps/(1-(1-p)s) \) \\ \hline
    CF & \( pe^{it}/(1-(1-p)e^{it}) \)\\ \hline
\end{tabular}
\end{center}

\subsection{Poisson}
Expresses the probability of a given number of events occurring in a fixed interval of time or space if these events occur with a known constant rate and independently of the time since the last event.
\begin{center}
\def\arraystretch{1.5}
\begin{tabular}{|r|l|} \hline
    Parameters & \( \lambda > 0 \) \\ \hline
    Support & \( \{0,1,2,\ldots\} \) \\ \hline
    PMF & \( \lambda^k e^{-\lambda}/k! \) \\ \hline 
    CDF & \( e^{-\lambda} \sum_{j=0}^{k} \lambda^j/j! \) \\ \hline
    Mean & \( \lambda \) \\ \hline
    Variance & \( \lambda \) \\ \hline
    PGF & \( \exp(\lambda(z-1)) \) \\ \hline
    CF & \( \exp(\lambda(e^{it}-1)) \)\\ \hline
\end{tabular}
\end{center}

\subsection{Exponential}
Describes times between events in a Poisson point process.
\begin{center}
\def\arraystretch{1.5}
\begin{tabular}{|r|l|} \hline
    Parameters & \( \lambda > 0 \) \\ \hline
    Support & \( [0,\infty) \) \\ \hline
    PDF & \( \lambda e^{-\lambda x} \) \\ \hline 
    CDF & \( 1-e^{- \lambda x} \) \\ \hline
    Mean & \( 1/\lambda \) \\ \hline
    Variance & \( 1/\lambda^2 \) \\ \hline
    CF & \( \lambda/(\lambda-it) \)\\ \hline
\end{tabular}
\end{center}


\pagebreak
\section{Table of Random (COUNTING??????) Processes}

\subsection{Poisson Point Process}
A process in which events occur continuously and independently at a constant average rate \note{IS THIS ENOUGH TO DESCRIBE PPP UNIQUELY?}

\subsubsection{Viewed as a Counting Process}
A counting process \( N = (N_t)_{t\geq 0} \) is a Poisson process with parameter \( \lambda \) if it has the properties,
\begin{enumerate}[nolistsep]
    \item \( N_0 = 0 \)
    \item independent increments
    \item the number of points in any time interval of length \( t \) is a Poisson random variable with parameter \( \lambda t \)
\end{enumerate}

In other words, a Poisson point process has probability mass function,
\begin{align*}
    \PP(N_t=n) = \frac{(\lambda t)^n}{n!}e^{-\lambda t}
\end{align*}

\subsubsection{Memoryless property} 
The distance between two consecutive points will be an exponential random variable with parameter \( \lambda \) (mean \( 1/\lambda \)).

\subsubsection{Probability of Jump}
\begin{align*}
    \PP(N_{t+s}=n+m | N_t =n) = 
    \begin{cases}
        1-\lambda s + \cO(s^2) & m = 0 \\
        \lambda s + \cO(s^2) & m = 1 \\
        \cO(s^2) & m \geq 1
    \end{cases} 
\end{align*}

\note{Something about exponentially distributed counting process}


%%%%%%%%%%%%%%%%%%%%%
%     CHAPTER 3     %
%%%%%%%%%%%%%%%%%%%%%
\pagebreak
\section{Generating and Characteristic functions}

how to get density from gen function



%%%%%%%%%%%%%%%%%%%%%
%     CHAPTER 4     %
%%%%%%%%%%%%%%%%%%%%%
\pagebreak
\section{Discrete Time Markov Chains}
\subsection{Transition Matrix}
\textit{Sample Problems}: 
\begin{itemize}[nolistsep]
    \item \hyperref[Exercise 4.1]{Exercise 4.1}: Write down transition matrices for processes based on rolling a dice
    \item \hyperref[Exercise 4.2]{Exercise 4.2}: Write down transition matrices for \( Y_n = X_{2n} \)
    \item \hyperref[Exercise 4.7]{Exercise 4.7}: Give example of transition matrix with multiple stationary distributions
\end{itemize}

\subsection{Classification of States}


\textit{Sample Problems}: 
\begin{itemize}[nolistsep]
    \item \hyperref[Exercise 4.3]{Exercise 4.3}: Show if all states communicate with an absorbing state they must all be transient
\end{itemize}

\subsection{Mean Recurence Time}

\textit{Sample Problems}: 
\begin{itemize}[nolistsep]
    \item \hyperref[Exercise 4.4]{Exercise 4.4}: Find expected visits to a state given some properties
    \item \hyperref[Exercise 4.5]{Exercise 4.5}: Find mean-recurrence times using invariant distribution
\end{itemize}

\subsection{Reversibility}
\textit{Sample Problems}: 
\begin{itemize}[nolistsep]
    \item \hyperref[Exercise 4.8]{Exercise 4.8}: Show process is reversible in equilibrium
\end{itemize}


\subsection{Stationary/Invariant distribution}

\note{TALK ABOUT VARIOUS METHODS FOR FINDING THIS}

\textit{Sample Problems}: 
\begin{itemize}[nolistsep]
    \item \hyperref[Exercise 4.5]{Exercise 4.5}: Find invariant distribution
    \item \hyperref[Exercise 4.6]{Exercise 4.6}: Find invariant distribution of mistakes in editions of a book by computing limit of generating function
    \item \hyperref[Exercise 4.7]{Exercise 4.7}: Give example of transition matrix with multiple stationary distributions
\end{itemize}

\subsection{Generating Functions}
\textit{Sample Problems}: 
\begin{itemize}[nolistsep]
    \item \hyperref[Exercise 4.6]{Exercise 4.6}: Find invariant distribution of mistakes in editions of a book by computing limit of generating function
\end{itemize}





\pagebreak
%%%%%%%%%%%%%%%%%%%%%
%     CHAPTER 5     %
%%%%%%%%%%%%%%%%%%%%%
\section{Continuous Time Markov Chains}

\subsection{Transition Matrix}


\subsection{Stationary/Invariant distribution}
Solve \( \pi P = \pi \) or \( \pi G = 0 \).
\textit{Sample Problems}: 
\begin{itemize}[nolistsep]
    \item \hyperref[Exercise 5.1]{Exercise 5.1}: Find invariant distribution and conditions for existence
    \item \hyperref[Exercise 5.2]{Exercise 5.2}: Show two processes have the same stationary distribution 
    \item \hyperref[Exercise 5.3]{Exercise 5.3}: Indirectly find stationary distribution by solving KFE, finding generating function for the chain, and computing the distribution of \( X_t \) as \( t\to\infty \)
\end{itemize}

\subsection{Generator}
\textit{Sample Problems}: 
\begin{itemize}[nolistsep]
    \item \hyperref[Exercise 5.1]{Exercise 5.1}: Write down generator
    \item \hyperref[Exercise 5.3]{Exercise 5.3}: Given generator find Generating function
    \item \hyperref[Exercise 5.4]{Exercise 5.4}: Write down generator and solve KFE/KBE
\end{itemize}

\subsection{KFE AND KBE}
Given infinitesimal generator \( G \) we have,
\begin{align*}
    \text{KFE}: && \dd{}{t}P_t = P_t G \\
    \text{KBE}: && \dd{}{t}P_t = GP_t
\end{align*}

\subsection{Generating Functions}
We can use the KFE and KBE to find the generating function of \( X_t \).


From definition,
\begin{align*}
    G_{X_t}(z) = \EE[z^{X_t} | X_0 = i] = \sum_{j=0}^{\infty} z^j p_t(i,j)
\end{align*}

It then follows that,
\begin{align*}
    \pp{}{t}G_{X_t}(z) = \sum_{j=0}^{\infty} s^j  \pp{}{t} p_{t}(i,j) 
    ,&&
    \pp{}{z}G_{X_t}(z) = \sum_{j=1}^{\infty} js^{j-1}p_t(i,j)
\end{align*}

\begin{enumerate}[nolistsep]
    \item Write down KFE or KBE equations
    \item Add equations together and PDE involving \( G_{X_t}(z) \), \( \partial_t G_{X_t}(z) \), and \( \partial_z G_{X_t}(z) \)
    \item Use initial condition \( G_{X_t}(z) = z^i \) (\(X_0 = i \)) to solve PDE
\end{enumerate}



\textit{Sample Problems}: 
\begin{itemize}[nolistsep]
    \item \hyperref[Exercise 5.3]{Exercise 5.3}: Use KBE to find PDE for generating function of \( X \)
    \item \hyperref[Exercise 5.4]{Exercise 5.4}: Use KBE to find PDE for generating function of \( X \)
    \item \hyperref[Exercise 5.5]{Exercise 5.5}: Compute generating function of Poisson process with random intensity. Use generating function to compute mean and variance.
\end{itemize}



\subsection{Finding PDEs}



\textit{Sample Problems}: 
\begin{itemize}[nolistsep]
    \item \hyperref[Exercise 5.3]{Exercise 5.3}: Given generator solve KFE
    \item \hyperref[Exercise 5.4]{Exercise 5.4}: Write down KFE and KBE and solve
\end{itemize}


\subsubsection{note{OTHER METHODS?}}

\subsection{Birth Death Processes}

General description of birth death processes

\subsubsection{General Form for infinite queue}
\textit{Description}:
\begin{itemize}[nolistsep]
    \item Process either jumps up one or down one or stay the same
    \item Expected wait time in state \( i \) is exponentially distributed \( \tau \sim \cE( \lambda_i + \mu_i) \)
    \item When the process does jump, the probability of an up jump is \( \lambda_i / (\lambda_i+\mu_i) \), and the probability of a down jump is \( \mu_i / (\lambda_i+\mu_i) \).
    \item if \( \lambda_0 > 0 \) the chain is irreducible.
\end{itemize}


\textit{State space}: \( S = \{1,2,3\ldots\}  \).

\textit{Generator}:
\begin{align*}
    G = \left[\begin{array}{cccccc}
        -\lambda_0 & \lambda_0 \\
        \mu_1 & -(\mu_1+\lambda_1) & \lambda_1 \\
        & \mu_2 & -(\mu_2+\lambda_2) & \lambda_2 \\
        && \mu_3 & -(\mu_3+\lambda_3) & \lambda_3 \\
        &&&  & \ddots &  
    \end{array}\right]
\end{align*}


\textit{Invariant distribution}:
\begin{align*}
    \pi(k) = \frac{\lambda_0 \lambda_1 \cdots \lambda_{k-1}}{\mu_1 \mu_2 \cdots \mu_k} \pi(0), 
    && \pi(0) = \left( 1+ \sum_{k=1}^{\infty}   \frac{\lambda_0 \lambda_1 \cdots \lambda_{k-1}}{\mu_1 \mu_2 \cdots \mu_k}  \right)^{-1}
\end{align*}


\textit{Sample Problems}: Example 5.2.9



\subsubsection{M/M/1 queue}
\textit{Description}:
\begin{itemize}[nolistsep]
\item Models infinite queue. 
\item Arrivals occur at a rate \( \lambda \) according to a Poisson process. 
\item Service times have exponential distribution with rate parameter \( \mu \), where \( 1/\mu \) is the mean service time.
\item A single server serves customers one at a time from front of queue, first come first serve
\end{itemize}


\textit{State space}: \( S = \{1,2,3\ldots\}  \).

\textit{Generator}:
\begin{align*}
    G = \left[\begin{array}{ccccc}
        -\lambda & \lambda \\
        \mu & -(\mu+\lambda) & \lambda \\
        & \mu & -(\mu+\lambda) & \lambda \\
        &&  & \ddots &  
    \end{array}\right]
\end{align*}


\textit{Invariant distribution}:
\begin{align*}
    \pi(k) = (1-\lambda/\mu)(\lambda/\mu)^k
\end{align*}

\textit{Expected Response Time}:
For customers who arrive and find the queue as a stationary process, the response time (sum of waiting and services times) has density function,
\begin{align*}
    f(t) = \begin{cases}
        (\mu-\lambda)e^{-(\mu-\lambda)t}, & t > 0 \\ 0 & \text{ow.}
    \end{cases} 
\end{align*}
This has mean,
\begin{align*}
    \int_0^\infty tf(t)\d t = \frac{1}{\mu - \lambda}
\end{align*}


\textit{Sample Problems}: 
\begin{itemize}[nolistsep]
    \item \hyperref[Exercise 5.1]{Exercise 5.1}: fdsaf sad
\end{itemize}


\subsubsection{M/M/\(\infty\)}
\textit{Description}:
\begin{itemize}[nolistsep]
\item Arrivals occur at a rate \( \lambda \) according to a Poisson process. 
\item Service times have exponential distribution with rate parameter \( \mu \), where \( 1/\mu \) is the mean service time.
\item There are always enough servers that every arriving job is serviced immediately.
\end{itemize}


\textit{State space}: \( S = \{1,2,3,\ldots\} \).

\textit{Generator}:
\begin{align*}
    G = \left[\begin{array}{cccccc}
        -\lambda & \lambda \\
        \mu & -(\mu+\lambda) & \lambda \\
        & 2\mu & -(2\mu+\lambda) & \lambda \\
        & & 3\mu & -(3\mu+\lambda) & \lambda \\
        && & & \ddots 
    \end{array}\right]
\end{align*}

\textit{Invariant Distribution}:
\begin{align*}
    \pi(k) = \frac{(\lambda/\mu)^ke^{-\lambda/\mu}}{k!}
\end{align*}


\textit{Sample Problems}: \hyperref[Exercise 5.3]{Exercise 5.3}, Final Problem ??, Practice Exam \#? Problem 1


\subsubsection{M/M/1/K queue}

\textit{State space}: \( S = \{1,2,\ldots, n\} \).

\textit{Generator}:
\begin{align*}
    G = \left[\begin{array}{cccccc}
        -\lambda & \lambda \\
        \mu & -(\mu+\lambda) & \lambda \\
        & \mu & -(\mu+\lambda) & \lambda \\
        \\
        && \ddots & \ddots & \ddots \\
        \\
        &&& \mu & -(\mu+\lambda) & \lambda \\
        &&&& \mu & -\mu
    \end{array}\right]
\end{align*}


%%%%%%%%%%%%%%%%%%%%%
%     CHAPTER 7     %
%%%%%%%%%%%%%%%%%%%%%
\pagebreak
\section{Brownian Motion}
\note{add examples from class notes}

\subsection{Martingale}
\textit{Sample Problems}: 
\begin{itemize}[nolistsep]
    \item \hyperref[Exercise 7.1]{Exercise 7.1}: Show a process is a Martingale using definition
    \item \hyperref[Exercise 7.4]{Exercise 7.4}: Show a process is a Martingale using definition
\end{itemize}

\subsection{Characteristic Functions}
\textit{Sample Problems}: 
\begin{itemize}[nolistsep]
    \item \hyperref[Exercise 7.2]{Exercise 7.2}: Compute characteristic function of \( W(N(t)) \), where \( N\sim \operatorname{Pois}(\lambda) \)
\end{itemize}

7.3: n-th variation time


\subsection{Laplace Transform}
\textit{Sample Problems}: 
\begin{itemize}[nolistsep]
    \item \note{Example ???} from book
    \item \hyperref[Exercise 7.4]{Exercise 7.4}: Compute Laplace transform of first hitting time.
\end{itemize}


%%%%%%%%%%%%%%%%%%%%%
%     CHAPTER 8     %
%%%%%%%%%%%%%%%%%%%%%
\pagebreak
\section{Stochastic Calculus}

\note{ITO FORMULA AND STUFF}
\subsection{It\^o's Formula}
\textit{One Dimension}:
\begin{align*}
    \d f(X_t) = f'(X_t)\d X_t + \frac{1}{2}f''(X_t)\d[X,X]_t
\end{align*}

\textit{Two Dimensions}:
\begin{align*}
    \d f(t,X_t) = f_t(t,X_t)\d t + f_x(t,X_t)\d X_t + \frac{1}{2}f_{xx}(t,X_t) \d[X,X]_t
\end{align*}

\textit{Two Dimensions}:
\begin{align*}
    \d f(X_t,Y_t) &= f_x(X_t,Y_t)\d X_t + f_y(X_t,Y_t)\d Y_t 
    \\&\hspace{3em} + \frac{1}{2} \Big( f_{xx}(X_t,Y_t)\d[X,X]_t + f_{xy}(X_t,Y_t)\d[X,Y]_t 
    \\&\hspace{6em}+ f_{yx}(X_t,Y_t)\d[Y,X]_t + f_{yy}(X_t,Y_t)\d[Y,Y]_t \Big)
\end{align*}

\subsection{Product Rule}
\begin{align*}
    \d(X_tY_t) = Y_t\d X_t + X_t \d Y_t + \d[X,Y]_t 
\end{align*}

\subsection{Girsanov's Theorem}

\textit{Sample Problems}:
\begin{itemize}[nolistsep]
    \item \hyperref[Practice Exam 4, Problem 2]{Practice Exam 4, Problem 2}
\end{itemize}


%%%%%%%%%%%%%%%%%%%%%
%     CHAPTER 9     %
%%%%%%%%%%%%%%%%%%%%%
\pagebreak
\section{SDEs and PDEs}
\note{unclassified}:
\hyperref[Exercise 9.4]{Exercise 9.1}
\hyperref[Exercise 9.4]{Exercise 9.4}
\hyperref[Exercise 9.5]{Exercise 9.5}
\hyperref[Exercise 9.6]{Exercise 9.6}

\hyperref[Exercise 9.7]{Exercise 9.7} (no solution for this)


\subsection{SDEs}

\textit{Sample Problems}:
\begin{itemize}[nolistsep]
    \item \hyperref[Exercise 9.3]{Exercise 9.3}: Use It\^o's Lemma to derive SDE for two new processes defined in terms of other processes
\end{itemize}


\subsubsection{Geometric Brownian Motion}


\subsubsection{Ornstein--Uhlenbeck (OU) process}
\textit{SDE}:
\begin{align*}
    \d X_t = \kappa(\theta-X_t)\d t + \sigma \d W_t
\end{align*}

\textit{Solution}:
\begin{align*}
    X_t = \theta + e^{-\kappa t}(X_0-\theta) + \int_0^t e^{-\kappa(t-s)}\sigma \d W_s
\end{align*}

\textit{Transition Density}:
\note{TODO}

\subsection{Infinitesimal Generator}
\label{sec:infgen}
Suppose \( X = (X_t)_{t\geq 0} \) is given by,
\begin{align*}
    X_t = \left[\begin{array}{c}\mu_1 \\ \mu_2 \\ \vdots \\ \mu_d \end{array}\right] \d t + \left[\begin{array}{cccc}\sigma_{1,1} & \sigma_{1,2} & \cdots & \sigma_{1,d} \\
        \sigma_{2,1} & & & \sigma_{2,d} \\
        \vdots & & & \vdots \\
        \sigma_{d,1} & \sigma_{d,2} & \cdots & \sigma_{d,d}
\end{array}\right]
\left[\begin{array}{c}\d W_t^1 \\ \d W_t^2 \\ \vdots \\ \d W_t^d\end{array}\right]
\end{align*}
where \( \mu_i \) and \( \sigma_{ij} \) depend on \( (t,X_t) \).

The infinitesimal generator of \( X \) is given by,
\begin{align*}
    \cA(t) = \sum_{i=1}^{d}\mu_i(t,x)\partial_{x_i} + \frac{1}{2} \sum_{i=1}^{d}\sum_{j=1}^{d} (\sigma\sigma^T)_{i,j}(t,X_t)\partial_{x_i} \partial_{x_j}
\end{align*}

\iffalse
In the 2d case,
\begin{align*}
    \sigma \sigma^T = \left[\begin{array}{cc} 
        \sigma_{1,1}^2+\sigma_{1,2}^2 & \sigma_{1,1}\sigma_{2,1} + \sigma_{1,2}\sigma_{2,2} \\
        \sigma_{1,1}\sigma_{2,1}+\sigma_{1,2}\sigma_{2,2} & \sigma_{2,1}^2 + \sigma_{2,2}^2
    \end{array}\right]
\end{align*}
\fi


\subsection{Kolmogorov Backwards Equation}
Let \( X = (X_t)_{t\geq 0} \) be the solution of an SDE of the form,
\begin{align*}
    \d X_t = \mu(t,X_t)\d t + \sigma(t,X_t)\d W_t
\end{align*}
where \( \mu:\RR_+\times\RR \to\RR^d  \) and \( \sigma:\RR_+\times\RR \to \RR^{d\times d} \).
For some suitible function \( \varphi \), define,
\begin{align*}
    u(t,X_t):= \EE[\varphi(X_T)|\cF_t]
\end{align*}
If \( u\in C^{1,2} \) then it satisfies the Kolmogorov Backward Equation,
\begin{align*}
    (\partial_t + \cA(t)) u(t,\cdot) = 0, && u(T,\cdot) = \varphi %, && \cA(t) = \mu(t,x) \partial_x + \frac{1}{2}\sigma^2(t,x)\partial^2_x
\end{align*}

\subsubsection{Speed and Scale Densities}
In one dimension, a time homogeneous process \( \d X_t = \mu(X_t) \d t + \sigma(X_t) \d W_t \) has generator,
\begin{align*}
    \cA(t) = \mu(x) \partial_x + \frac{1}{2}\sigma^2(x)\partial_x^2
\end{align*}

We can write this as,
\begin{align*}
    \cA = \frac{1}{m(x)}\partial_x \left( \frac{1}{s(x)}\partial_x \right)
\end{align*}
where \( s(x) \) and \( m(x) \) are respectively called the scale and speed densities, and are given by,
\begin{align*}
    s(x) = \exp \left( - 2\int \frac{\mu(x)}{\sigma^2(x)}d\ x \right)
    ,&& m(x) = \frac{2}{\sigma^2(x)} \exp \left( 2\int \frac{\mu(x)}{\sigma^2(x)}\d x \right)
\end{align*}

If \( m \) is normalizable then \( m \) is a time-homogeneous solution to the KFE and a stationary density for \( X \).


\subsubsection{Computing Solution to KBE for 1d Time Homogeneous Process}
\begin{enumerate}[nolistsep]
    \item Write down \( \cA \)
    \item Write down speed density \( m(x) \)
    \item Find complete set of eigenfunctions, \( \{ \psi_n \} \) of \( \cA \) satisfying, \( \cA \psi_n = \lambda_n\psi_n \)
    \item Normalize eigenvectors wrt. \( m \) so that \( \ip{\psi_n,\psi_n}_m = 1 \).
    \item Compute,
        \begin{align*}
            u(t,x) = \sum_{n} e^{(T-t)\lambda_n} \ip{\psi_n,\varphi}_m\psi_n
        \end{align*}
\end{enumerate}

\subsection{Transition Density}
The transition density is defined as,
\begin{align*}
    \Gamma(t,x;T,y) = \PP(X_T\in\d y | X_t=  x)
\end{align*}
and satisfies,
\begin{align*}
    \text{KBE}: && (\partial_t + \cA(t)) \Gamma(t,\cdot;T,y) = 0, && \Gamma(T,\cdot;T,y) = \delta_y \\
    \text{KFE}: && (-\partial_T + \cA^*(T)) \Gamma(t,x;T,\cdot) = 0, && \Gamma(T,x;T,\cdot) = \delta_x
\end{align*}


\subsubsection{Computing Transition Density}
\note{WHAT KIND OF BC DO WE NEED???}

\begin{enumerate}[nolistsep]
    \item Write down \( \cA \)
    \item Write down speed density \( m(x) \)
    \item Find complete set of eigenfunctions, \( \{ \psi_n \} \) of \( \cA \) satisfying, \( \cA \psi_n = \lambda_n\psi_n \)
    \item Normalize eigenvectors wrt. \( m \) so that \( \ip{\psi_n,\psi_n}_m = 1 \).
    \item Compute,
        \begin{align*}
            \Gamma(t,x;T,y) = m(y)\sum_{n} e^{(T-t)\lambda_n} \psi_n(y)\psi_n(x)
        \end{align*}
\end{enumerate}

\textit{Sample Problems}:
\begin{itemize}[nolistsep]
    \item \hyperref[Practice Exam 4, Problem 2]{Practice Exam 4, Problem 2}: Find transition density for constant coefficient process.
    \item \hyperref[Practice Exam 5, Problem 2]{Practice Exam 5, Problem 2}: Find transition density for mean repelling OU process (two different approaches)
\end{itemize}



\subsection{Finding PDEs Using Martingale Process}
\begin{enumerate}[nolistsep]
    \item Find a martingale process depending on \( u(t,X_t) \).
    \item Take the differential of it.
    \item Set the \( \d t \) term to zero.
\end{enumerate}

This will give a PDE which \( u(t,X_t) \) satisfies.

\textit{Sample Problems}:
\begin{itemize}[nolistsep]
    \item Theorem 9.2.1: Derive KBE
    \item Theorem 9.2.2: Derive PDE for process,
        {\small
        \begin{align*}
            u(t,X_t) = \EE \left[ e^{-A(t,T)}\varphi(X_T) + \int_t^T e^{-A(t,s)}g(s,X_s) | \cF_t \right], && A(t,s) = \int_t^s \gamma(u,X_u)\d u
        \end{align*}
        }
    \item \hyperref[Exercise 9.2]{Exercise 9.2}: Find PDE for given expression (solutions given using theorem and by finding martingale)
\end{itemize}


\subsection{Finding PDEs for Hitting Time Problems}
Given a process \( X = (X_t)_{t\geq 0} \) and some region \( R \), define,
\begin{align*}
    \tau = \operatorname{inf}\{t \geq 0 : X_t \notin R \}
\end{align*}

Define,
\begin{align*}
    u(x) = \EE \left[ e^{-\lambda(\tau - t)} \varphi(X_\tau) + \int_t^\tau e^{-\lambda(s-t)}g(X_s)\d s \bigg| X_t = x \right], && t \leq \tau 
\end{align*}

Assuming \( \PP(\tau < \infty) = 1 \), the function \( u \) satisfies,
\begin{align*}
    (\cA - \lambda) u = 0, && u = \varphi \text{ on }\partial R
\end{align*}
where \( \cA \) is the \hyperref[sec:infgen]{infinitesimal generator} of \( X \).

\textit{Sample Problems}:
\begin{itemize}[nolistsep]
    \item Theorem 9.4.1: This is that theorem
    \item Corollary 9.4.2: Find Laplace transform of \( \tau \)
    \item Example 9.4.3: First hitting time of Brownian motion
    \item \hyperref[Practice Exam 1, Problem 2]{Practice Exam 1, Problem 2}: Find PDE for hitting time of 2d process.
\end{itemize}


\note{ADD ASSOCIATED PDEs}



%%%%%%%%%%%%%%%%%%%%%
%     CHAPTER 10    %
%%%%%%%%%%%%%%%%%%%%%
\pagebreak
\section{Jump Diffusions}



\pagebreak
\section{Practice Qualification Exams}
\include{practice_quals}

\pagebreak
\section{Homework Problems}
\include{ch3}
\include{ch4}
\include{ch5}
\include{ch6}
\include{ch7}
\include{ch8}
\include{ch9}
\include{ch10}



\end{document}
